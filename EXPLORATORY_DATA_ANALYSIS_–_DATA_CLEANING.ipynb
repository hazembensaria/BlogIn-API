{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hazembensaria/BlogIn-API/blob/main/EXPLORATORY_DATA_ANALYSIS_%E2%80%93_DATA_CLEANING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXPLORATORY DATA ANALYSIS â€“ DATA CLEANING"
      ],
      "metadata": {
        "id": "mkRHIvM06yZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will demonstrate Data Cleaning as part of Exploratory Data Analysis (EDA). We will work on a modified version of the cardiovascular dataset from Kaggle (https://www.kaggle.com/code/sulianova/eda-cardiovascular-data/data). The dataset consists of 70000 records of patient data in 12 features. The target class \"cardio\" equals 1, when a patient has cardiovascular disease, and it's 0 if a patient is healthy."
      ],
      "metadata": {
        "id": "-DapbW18f-Zt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "DcZDdukne9go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to import some libraries that will be used during data cleaning."
      ],
      "metadata": {
        "id": "p8IHjsB_NJ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import rcParams\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LXO2d36eNJSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "y3w73IED3CyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Clone the dataset Repository***\n",
        "\n",
        "The modified dataset can be cloned from the GitHub repository https://github.com/mkjubran/AIData.git as below"
      ],
      "metadata": {
        "id": "YkNaY9Pl3Tfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./AIData\n",
        "!git clone https://github.com/mkjubran/AIData.git"
      ],
      "metadata": {
        "id": "Q913_8qtKfPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Read the dataset***\n",
        "\n",
        "The data is stored in the cardio_train.csv file. Read the input data into a dataframe using the Pandas library (https://pandas.pydata.org/) to read the data."
      ],
      "metadata": {
        "id": "FYe9U8mrMcqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/AIData/cardio_train_modified.csv\",sep=\";\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LdJFnrziMdl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Display Data Info and Check NAN***\n",
        "\n",
        "To display the content of the data and type of features use the info() method"
      ],
      "metadata": {
        "id": "Ea4lRShuYjBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "y2UGE3RsYoLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the dataframe consists of 70000 rows with 12 variables (features). Ten features are numerical and two features are objects (gender, smoke). We notice that for some of the features the number of non-null values does not equal 70000 which means that some feature values in the data are missing.\n",
        "\n",
        "We can get the exact number of missing values for each feature using the isnull() method as below"
      ],
      "metadata": {
        "id": "HhqXkiZra8PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "kXV9LNxccgFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also get the number and percentage of patients' records that has one or more missing values"
      ],
      "metadata": {
        "id": "49UJsVbZ48ZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().any(axis=1).sum())\n",
        "print(100*df.isnull().any(axis=1).sum()/df.shape[0],'%')"
      ],
      "metadata": {
        "id": "BR5M6mwW4873"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To display the records with NAN values"
      ],
      "metadata": {
        "id": "XRh5km2u7hzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.isnull().any(axis=1)]"
      ],
      "metadata": {
        "id": "sYLytc857Yp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "tizgKxAHRl5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: drop all empty records**"
      ],
      "metadata": {
        "id": "sNpavSHHRsBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step is usually to drop all empty records. I.e. records with all features are NaN."
      ],
      "metadata": {
        "id": "slsyL5n6B5e-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(how='all', inplace=True)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "IRj5nkzjC31b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By comparing the number of NaN features before and after the last step, we notice that there were 3 empty records in the dataset. We notice also that the number of missing values for the features 'weight', 'ap_hi', ap_lo', and 'gluc' is very low. So the best choice is to delete these patients' records from the dataset."
      ],
      "metadata": {
        "id": "DI_uEUsMDWRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: target feature (class, label)**\n",
        "\n",
        "The target feature (class, label) \"cardio\" equals 1, when a patient has cardiovascular disease, and it's 0 if a patient is healthy. Notice that this feature 'cardio' does not have any missing data. Had there been any missing values in the target feature, then the corresponding patient records must be dropped."
      ],
      "metadata": {
        "id": "3Flaa0g1t8Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.dropna(subset=['cardio'], inplace=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "DxzRXmS6vgwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected no record is dropped."
      ],
      "metadata": {
        "id": "gkCG-_WhvqLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'weight' feature**"
      ],
      "metadata": {
        "id": "0k95ZG5iR6U_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the patients' records with 'weight' feature is NaN"
      ],
      "metadata": {
        "id": "s16fIXMr9E2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.weight.isnull()]"
      ],
      "metadata": {
        "id": "YccgPbZd8joO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the patients' records with 'weight' feature is not NaN"
      ],
      "metadata": {
        "id": "HMkKTbji_ReS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.weight.notna()]"
      ],
      "metadata": {
        "id": "30v15gys_LAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete (drop) records with 'weight' feature is NaN be selecting only rows with weight does not equal to NaN."
      ],
      "metadata": {
        "id": "vuHfhyW49iGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.dropna(subset=['weight'], inplace=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "lccy3XFt-ExP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "zJlPXA_M_3W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed the number of records in the data frame was reduced by 4 (69996) and there is no NAN value in the 'weight' feature"
      ],
      "metadata": {
        "id": "G6XLHFzg_nzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'ap_hi', ap_lo', and 'gluc' features**"
      ],
      "metadata": {
        "id": "GEAvVchuSLfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will do the same for the 'ap_hi', ap_lo', and 'gluc' features."
      ],
      "metadata": {
        "id": "71x2ZqHwAICj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.dropna(subset=['ap_hi','ap_lo','gluc'], inplace=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "Sl6g9LCYETkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "0t7xluvsAf7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'gender' feature**"
      ],
      "metadata": {
        "id": "ujzyliWPgrt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gender feature is a string 'male, female' and we have many missing values. One option is to drop all records with 'gender' feature equals to 'NaN'. However this means dropping ~1.4% of the records and this is to be decided by the domain experts."
      ],
      "metadata": {
        "id": "tF97qFWPAiJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfgender = df.copy()\n",
        "print(dfgender.isnull()['gender'].sum())\n",
        "print(100*dfgender.isnull()['gender'].sum()/dfgender.shape[0],'%')\n",
        "print(dfgender.shape)\n",
        "dfgender.dropna(subset=['gender'], inplace=True)\n",
        "print(dfgender.shape)"
      ],
      "metadata": {
        "id": "8cRP3C98MZ5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another option is to replace all missing values in the 'gender' feature with the majority kind (male or female)."
      ],
      "metadata": {
        "id": "UvStd2oDMNtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['gender'].value_counts()"
      ],
      "metadata": {
        "id": "DIkCAEnaE8_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfc = df.copy()\n",
        "dfc['gender'].fillna(value='female', inplace=True)\n",
        "dfc['gender'].value_counts()"
      ],
      "metadata": {
        "id": "p-sA6WN9G28A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed the number of female records increased.\n",
        "\n",
        "A third option is to try to set the missing 'gender' feature values based on other values in the record. For example, we can check the correlation between 'gender' and 'height' features."
      ],
      "metadata": {
        "id": "r71taUcbH7ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['gender','height']].apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "76op9QTUI0-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that there is not much correlation. Let us try to check with other features."
      ],
      "metadata": {
        "id": "QUJx5LrmJci2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "Xd8ivdnyJHK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that the 'gender' feature has the highest correlation with the 'smoke' feature."
      ],
      "metadata": {
        "id": "Iyp4JAO_Jk_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['gender','smoke']].apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "UOd5-ASKJ5MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us explore the correlation using crosstab"
      ],
      "metadata": {
        "id": "gETDiuhmJ7lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df['gender'],df['smoke'])"
      ],
      "metadata": {
        "id": "wZBfYsOzKL7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This implies that most non-smokers are females and most smokers are males in the dataset. So let us make all 'gender' feature with 'NaN values for smokers to be 'male', and all 'gender' feature with 'NaN values for non-smokers to be 'female'."
      ],
      "metadata": {
        "id": "DrGH9VvELDy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfsmoke = df.copy()\n",
        "dfsmoke.loc[(dfsmoke.gender.isnull()) & (dfsmoke['smoke'] == 'Yes'),'gender']='male'\n",
        "dfsmoke.loc[(dfsmoke.gender.isnull()) & (dfsmoke['smoke'] == 'No'),'gender']='female'"
      ],
      "metadata": {
        "id": "7Ui91Kl4Ga5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us check the correlation using crosstab again."
      ],
      "metadata": {
        "id": "3d4x5EC6KBhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(dfsmoke['gender'],dfsmoke['smoke'])"
      ],
      "metadata": {
        "id": "CvrUG87qJfFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the number of female non-smokers increased and the male smokers increase also. We also need to check if there are still any 'NaN' values in the 'gender' feature. This could be because the 'smoke' feature has also NaN values."
      ],
      "metadata": {
        "id": "M9dtZGEnKR5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfsmoke.isnull().sum()"
      ],
      "metadata": {
        "id": "2nGaE1DnKXiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 12 NaN values in the 'gender' feature. We will drop them because they make only very small percentage of the population (records in the dataset)."
      ],
      "metadata": {
        "id": "cwgjTHJ8K3sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dfsmoke.shape)\n",
        "dfsmoke.dropna(subset=['gender'], inplace=True)\n",
        "print(dfsmoke.shape)"
      ],
      "metadata": {
        "id": "vpuLXKQ2LLF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will consider the third option to deal with the 'NaN' values in the 'gender' feature."
      ],
      "metadata": {
        "id": "CGKuv5uKKcPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = dfsmoke.copy()\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "hY640BNhRbQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'smoke' feature**"
      ],
      "metadata": {
        "id": "HgD-mEXqUnPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now handle the missing vlues of the 'smoke' feature. This feature takes only two values 'Yes' and 'No'. Is there any correlation with the other features?"
      ],
      "metadata": {
        "id": "Mplvu1AVUqYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "QbmXcNmbUtvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there is a high correlation between the 'smoke' feature and both the 'gender' and 'alco' features. But since we already used the 'smoke' feature to deal with the NaN values in the 'gender' feature and thus the correlation between them might be affected, we will use the 'alco' feature to deal with the NaN values in the 'smoke' feature."
      ],
      "metadata": {
        "id": "M4LjDwN8VH-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df['smoke'],df['alco'])"
      ],
      "metadata": {
        "id": "Yj-m0YaxVuMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe from the crosstab results that most non-alcoholic persons in the dataset are non-smokers but alcoholic persons might or might not be smokers. So we will make all 'NaN' values in the 'smoke' feature for all records of non-alcoholic persons to be No."
      ],
      "metadata": {
        "id": "RFRA_nnyV3n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[(df.smoke.isnull()) & (df['alco'] == 0.0),'smoke']='No'"
      ],
      "metadata": {
        "id": "fhoNXlGxW09c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us check the correlation using crosstab again."
      ],
      "metadata": {
        "id": "7fIW1s1QXYkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df['smoke'],df['alco'])"
      ],
      "metadata": {
        "id": "PhEgjpcLXT0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the number of non-alcoholic persons in the dataset is non-smokers increased. Let us know check the status of the missing values."
      ],
      "metadata": {
        "id": "M-wz1ZDFXc1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "s5Pd1xe2gqCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the number of remaining missing values of the 'smoke' feature is small, we will drop all other records with the 'smoke' feature equal to NaN."
      ],
      "metadata": {
        "id": "NVWKG8Lpg5_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.dropna(subset=['smoke'], inplace=True)\n",
        "print(df.shape)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "gN8zCQigZoVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'cholesterol' feature**"
      ],
      "metadata": {
        "id": "V6_acJYAaphM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now handle the missing vlues of the 'cholesterol' feature. This feature takes three values."
      ],
      "metadata": {
        "id": "utfT8QTIas0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.cholesterol.unique()"
      ],
      "metadata": {
        "id": "yWYnuKmca_gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Is there any correlation with the other features?"
      ],
      "metadata": {
        "id": "nIXSGF2fbL_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "-f4IeLNObKSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there is a high correlation between the 'alco' feature and the 'gluc' feature. Let us explore the correlation using crosstab."
      ],
      "metadata": {
        "id": "2UDoMOh7bVIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(pd.crosstab(df['cholesterol'],df['gluc'])/pd.crosstab(df['cholesterol'],df['gluc']).sum())*100"
      ],
      "metadata": {
        "id": "7Tzol3MCb8TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that 81% of the persons with a 'gluc' value of 1.0 has also a 'cholesterol' value of 1.0. We also observe that 65% of the persons with a 'gluc' value of 3.0 has also a 'cholesterol' value of 3.0. And thus we will use these two notes to handle missing values of the 'cholesterol' feature. However, for the persons with a 'gluc' value of 2.0, 43% and 46% have 'cholesterol values of 1.0 and 2.0 which imply that we can not use the 'gluc' value for these persons to handle missing 'cholesterol' values."
      ],
      "metadata": {
        "id": "xfmW1kbscCHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[(df.cholesterol.isnull()) & (df['gluc'] == 1.0),'cholesterol']=1.0\n",
        "df.loc[(df.cholesterol.isnull()) & (df['gluc'] == 3.0),'cholesterol']=3.0"
      ],
      "metadata": {
        "id": "MKrvsUBzeV0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now check the status of missing values"
      ],
      "metadata": {
        "id": "O4Mz0gzKfOwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "i1x4ZN6UfMwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the number of missing values in the 'cholesterol' feature is reduced to 39. Then we will remove these records from the dataset."
      ],
      "metadata": {
        "id": "8pK4Gw0DfYRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.dropna(subset=['cholesterol'], inplace=True)\n",
        "print(df.shape)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "_VZbICsKfo59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'height' feature**"
      ],
      "metadata": {
        "id": "03DDV6d-Sko4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, for the 'height' feature, is there any correlation with the other features?"
      ],
      "metadata": {
        "id": "Evd_QkGKSwk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "r0Eu30f9S_KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there is a high correlation between the 'height' feature and both the 'gender' and 'weight' features. However, the 'height' feature has a continuous value and we can not deal with it similar to the 'gender' feature'. Instead, we should create a model that predicts the 'height' feature based on the 'gender' and 'weight' features which we will study in the next modules. So, for now, we have two options, either to drop all records where the 'height' feature is NaN or replace all these NaN values with some statistical measure (mean, median) of the 'height' feature. In this notebook, we will replace the NaN values with the median of the values in the 'height' feature."
      ],
      "metadata": {
        "id": "THhi8dlWTdrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.height.median())\n",
        "df['height'].fillna(df.height.median(), inplace=True)\n",
        "print(df.height.median())\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "E5mwkPkPUWxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove Outliers"
      ],
      "metadata": {
        "id": "SxMxobhoAPA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us have a close look at the statistical properties of the numaric features"
      ],
      "metadata": {
        "id": "xlI-m0y_AVxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "uVxi4Ql9Amfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually, the 'id' feature will not have outliers, so let us check the 'age' feature. According to the description of the dataset, the age is in days. Let us convert the Age into years so that it is easier to understand and interpret."
      ],
      "metadata": {
        "id": "Dam4xa7eB0LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['age_years'] = (df['age'] / 365).round().astype('int')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Nb1hkh1SEVkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us have a close look again at the statistical properties of the numaric features"
      ],
      "metadata": {
        "id": "NPNvRQS3EijG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "q8tHIQa_BpSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The minimum age in the datset is about 30 years, the maximum is about 65 years, and the average is about 53.33 years."
      ],
      "metadata": {
        "id": "r90Je8pECGWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Outliers: 'height' and 'weight' feature**\n",
        "\n",
        "Next, let us examine the 'height' feature, the minimum height is 55cm which is too short for the records of persons with a minimum age of 30. Similarly, the maximum height is 250cms which is too rare value for a person's height. So there must be an error in the height feature. Let us also examine the 'weight' feature. The minimum weight is 10 kg which is too low for the records of persons with a minimum age of 30. So again, there must be an error in the 'weight' feature. Let us get the box plot of these two features."
      ],
      "metadata": {
        "id": "lCse5NWlCn2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 10, 6\n",
        "df.boxplot(column=['height', 'weight'])"
      ],
      "metadata": {
        "id": "IkRa_lWqD98-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed there are outliers, so let us remove weights and heights, that fall below 5% or above 95% of a given range."
      ],
      "metadata": {
        "id": "dF-eZV9gGSKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df[(df['height'] > df['height'].quantile(0.95)) | (df['height'] < df['height'].quantile(0.05))].index,inplace=True)\n",
        "df.drop(df[(df['weight'] > df['weight'].quantile(0.95)) | (df['weight'] < df['weight'].quantile(0.05))].index,inplace=True)"
      ],
      "metadata": {
        "id": "pGyRMYGUGfpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us get the box plot of these two features again."
      ],
      "metadata": {
        "id": "Y8vVtct3HBQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 10, 6\n",
        "df.boxplot(column=['height', 'weight'])"
      ],
      "metadata": {
        "id": "loJ7zofRHAhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed, the outliers for the 'height' and 'weight' features are removed."
      ],
      "metadata": {
        "id": "BbgbNWFXA-tS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Outliers: 'ap_hi' and 'ap_lo' feature**\n",
        "\n",
        "Similarly, we will do the same for the 'ap_hi' and 'ap_lo' features especially since the blood pressure can not be negative. Below is the box plot for the 'ap_hi' and 'ap_lo' features."
      ],
      "metadata": {
        "id": "BducBqYizknF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 10, 6\n",
        "df.boxplot(column=['ap_hi', 'ap_lo'])"
      ],
      "metadata": {
        "id": "1QEKFWT0vy8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will remove 'ap_hi' and 'ap_hi' features that fall below 5% or above 95% of a given range."
      ],
      "metadata": {
        "id": "ldRDsrTHyy2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df[(df['ap_hi'] > df['ap_hi'].quantile(0.95)) | (df['ap_hi'] < df['ap_hi'].quantile(0.05))].index,inplace=True)\n",
        "df.drop(df[(df['ap_lo'] > df['ap_lo'].quantile(0.95)) | (df['ap_lo'] < df['ap_lo'].quantile(0.05))].index,inplace=True)"
      ],
      "metadata": {
        "id": "rhK8t4NRyXez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we plot again the box plot of the 'ap_hi' and 'ap_lo' features."
      ],
      "metadata": {
        "id": "luo39o09zAo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 10, 6\n",
        "df.boxplot(column=['ap_hi', 'ap_lo'])"
      ],
      "metadata": {
        "id": "l3xkRLK5wSho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed, the outliers for the 'height' and 'weight' features are removed. Let us also make sure that the systolic pressure 'ap_hi' is always higher than the diastolic pressure 'ap_lo'."
      ],
      "metadata": {
        "id": "p3GLdpeK1REj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Systolic pressure is higher than diastolic pressure in {0}% of the patient records\".format(100*df[df['ap_hi']> df['ap_lo']].shape[0]/df.shape[0]))"
      ],
      "metadata": {
        "id": "DrSfsZtB1PJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Outliers: the other features**\n",
        "\n",
        "The values of the other features are limited within a small range as can be observed from the min and max values in the statistical description table. Let us check if these features take only discrete values."
      ],
      "metadata": {
        "id": "zMr1aNHm4nnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('The discrete values of the \\'cholesterol\\' feature are {}'.format(set(df['cholesterol'].unique())))\n",
        "print('The discrete values of the \\'gluc\\' feature are {}'.format(set(df['gluc'].unique())))\n",
        "print('The discrete values of the \\'active\\' feature are {}'.format(set(df['active'].unique())))"
      ],
      "metadata": {
        "id": "TQIsmK525qF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the range of the other features is limited and the values are discrete so no need to apply outliers removal techniques for these features."
      ],
      "metadata": {
        "id": "EQwnJRgA7LAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Data"
      ],
      "metadata": {
        "id": "-SEz47bidar5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will save the clean dataset into a CSV file to be used in the next session."
      ],
      "metadata": {
        "id": "boXoDJ1hdfQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/AIData/cardio_train_cleaned.csv\",sep=\";\",index=False)"
      ],
      "metadata": {
        "id": "sgb3CQnGd9il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the '/content/AIData/' folder for the 'cardio_train_cleaned.csv' file and download it for future usage."
      ],
      "metadata": {
        "id": "itbI0J9ZeKPB"
      }
    }
  ]
}